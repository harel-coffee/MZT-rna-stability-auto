{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GradientBoostinRegressor to generate the predictions intervals\n",
    "\n",
    "\n",
    "Here, we train the Gradient Boosting that optimizes the `loss=\"quantile\", alpha=0.5` that is the predicted median, the idea is to find the best set of hyperparameters that optimize this metric. Then I will train with the found hyperparameters a model to produce the upper and lower prediction intervals.\n",
    "\n",
    "Here, I determine the optimal hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import random_integers\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "\n",
    "# my module imports\n",
    "from optimalcodon.projects.rnastability.dataprocessing import get_data, general_preprocesing_pipeline\n",
    "from optimalcodon.projects.rnastability import modelevaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67817 points for training and 7534 for testing with 6 features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(67817, 80)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD TRAINING DATA\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = get_data(\"../19-04-30-PredictiveModelDecayAllSpecies/19-04-30-EDA/results_data/\")\n",
    "\n",
    "print(\"{} points for training and {} for testing with {} features\".format(\n",
    "    train_x.shape[0], test_x.shape[0], test_x.shape[1]))\n",
    "\n",
    "# pre-processing\n",
    "\n",
    "preprocessing = general_preprocesing_pipeline(train_x)\n",
    "\n",
    "preprocessing.fit(train_x)\n",
    "train_x_transformed = preprocessing.transform(train_x)\n",
    "\n",
    "train_x_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done   1 tasks      | elapsed: 17.9min\n",
      "[Parallel(n_jobs=30)]: Done  12 tasks      | elapsed: 68.7min\n",
      "[Parallel(n_jobs=30)]: Done  25 tasks      | elapsed: 116.7min\n",
      "[Parallel(n_jobs=30)]: Done  38 tasks      | elapsed: 156.7min\n",
      "[Parallel(n_jobs=30)]: Done  53 tasks      | elapsed: 196.4min\n",
      "/home/smedina/anaconda3/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=30)]: Done  68 tasks      | elapsed: 222.0min\n",
      "[Parallel(n_jobs=30)]: Done  85 tasks      | elapsed: 286.4min\n",
      "[Parallel(n_jobs=30)]: Done 102 tasks      | elapsed: 348.2min\n",
      "[Parallel(n_jobs=30)]: Done 121 tasks      | elapsed: 405.1min\n",
      "[Parallel(n_jobs=30)]: Done 140 tasks      | elapsed: 471.2min\n",
      "[Parallel(n_jobs=30)]: Done 161 tasks      | elapsed: 528.0min\n",
      "[Parallel(n_jobs=30)]: Done 182 tasks      | elapsed: 596.5min\n",
      "[Parallel(n_jobs=30)]: Done 205 tasks      | elapsed: 666.6min\n",
      "[Parallel(n_jobs=30)]: Done 228 tasks      | elapsed: 776.5min\n",
      "[Parallel(n_jobs=30)]: Done 253 tasks      | elapsed: 840.6min\n",
      "[Parallel(n_jobs=30)]: Done 278 tasks      | elapsed: 885.3min\n",
      "[Parallel(n_jobs=30)]: Done 327 out of 350 | elapsed: 1000.9min remaining: 70.4min\n",
      "[Parallel(n_jobs=30)]: Done 350 out of 350 | elapsed: 1184.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                   error_score='raise-deprecating',\n",
       "                   estimator=GradientBoostingRegressor(alpha=0.5,\n",
       "                                                       criterion='friedman_mse',\n",
       "                                                       init=None,\n",
       "                                                       learning_rate=0.1,\n",
       "                                                       loss='quantile',\n",
       "                                                       max_depth=3,\n",
       "                                                       max_features=None,\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_spl...\n",
       "                   iid='warn', n_iter=70, n_jobs=30,\n",
       "                   param_distributions={'learning_rate': [0.1, 0.055, 0.01,\n",
       "                                                          0.0055, 0.001],\n",
       "                                        'max_depth': [10, 15, 17, 20],\n",
       "                                        'max_features': ['log2'],\n",
       "                                        'min_samples_leaf': [2, 3],\n",
       "                                        'min_samples_split': [4, 6, 8],\n",
       "                                        'n_estimators': [500, 700, 1000, 1200,\n",
       "                                                         1500, 1700, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='r2', verbose=10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_grid = {\n",
    "          'learning_rate':[0.1, 0.055, 0.01, 0.0055, 0.001],\n",
    "          'n_estimators':[500, 700,1000, 1200, 1500, 1700, 2000],\n",
    "          'min_samples_split':[4, 6, 8],\n",
    "          'min_samples_leaf':[2, 3],\n",
    "          'max_depth':[10, 15, 17, 20],\n",
    "          'max_features':['log2']}\n",
    "\n",
    "# make cross validation to shuffle the data\n",
    "cross_val = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "model = GradientBoostingRegressor(loss='quantile', alpha=0.5)\n",
    "random_cv = RandomizedSearchCV(estimator=model,\n",
    "                               param_distributions=gbm_grid,\n",
    "                               cv=cross_val, n_iter=70, n_jobs=30,verbose=10,\n",
    "                               scoring='r2')\n",
    "\n",
    "random_cv.fit(train_x_transformed, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36542181074940194"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1700,\n",
       " 'min_samples_split': 4,\n",
       " 'min_samples_leaf': 3,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 17,\n",
       " 'learning_rate': 0.01}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.5, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.01, loss='quantile', max_depth=17,\n",
       "                          max_features='log2', max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=3, min_samples_split=4,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=1700,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
