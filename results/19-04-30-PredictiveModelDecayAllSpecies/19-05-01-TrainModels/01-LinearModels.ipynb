{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Linear Models\n",
    "\n",
    "Evaluate Linear Models\n",
    "\n",
    "Here, I evaluate the following linear models:\n",
    "\n",
    "+ LinearRegression\n",
    "+ PLSRegression\n",
    "+ Lasso\n",
    "+ Enet\n",
    "\n",
    "## NOTE:\n",
    "\n",
    "For linear models I will add polynomial features of 2nd degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn import\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "# my module imports\n",
    "from optimalcodon.projects.rnastability.dataprocessing import get_data, general_preprocesing_pipeline\n",
    "from optimalcodon.projects.rnastability import modelevaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = get_data(\"../19-04-30-EDA/results_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67817 points for training and 7534 for testing with 6 features\n"
     ]
    }
   ],
   "source": [
    "print(\"{} points for training and {} for testing with {} features\".format(\n",
    "    train_x.shape[0], test_x.shape[0], test_x.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process Pipeline\n",
    "\n",
    "preprocessing = Pipeline([\n",
    "    ('general', general_preprocesing_pipeline(train_x)), # see the code for general_preprocesing_pipeline\n",
    "    ('polyfeaturs', PolynomialFeatures(degree=2)),\n",
    "    ('zerovar', VarianceThreshold(threshold=0.0)),\n",
    "    ('scaling', StandardScaler()) # I scale again not all polynomial features may be with scaled\n",
    "])\n",
    "\n",
    "\n",
    "preprocessing.fit(train_x)\n",
    "train_x_transformed = preprocessing.transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67817, 3320)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done   3 out of   3 | elapsed:  2.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done   3 out of   3 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score R2 =  0.1706582260853268\n",
      "Best Parameters:  {}\n"
     ]
    }
   ],
   "source": [
    "lm_reg = Pipeline([\n",
    "    ('lm', LinearRegression())\n",
    "])\n",
    "\n",
    "lm_grid = dict()\n",
    "\n",
    "lm_search = modelevaluation.gridsearch(lm_reg, lm_grid, train_x_transformed, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## PLS regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done   3 out of  27 | elapsed:  1.2min remaining:  9.6min\n",
      "[Parallel(n_jobs=32)]: Done   6 out of  27 | elapsed:  1.3min remaining:  4.4min\n",
      "[Parallel(n_jobs=32)]: Done   9 out of  27 | elapsed:  1.3min remaining:  2.7min\n",
      "[Parallel(n_jobs=32)]: Done  12 out of  27 | elapsed:  1.4min remaining:  1.8min\n",
      "[Parallel(n_jobs=32)]: Done  15 out of  27 | elapsed:  1.5min remaining:  1.2min\n",
      "[Parallel(n_jobs=32)]: Done  18 out of  27 | elapsed:  1.5min remaining:   46.2s\n",
      "[Parallel(n_jobs=32)]: Done  21 out of  27 | elapsed:  1.6min remaining:   27.3s\n",
      "[Parallel(n_jobs=32)]: Done  24 out of  27 | elapsed:  1.7min remaining:   12.4s\n",
      "[Parallel(n_jobs=32)]: Done  27 out of  27 | elapsed:  1.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done  27 out of  27 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score R2 =  0.19312240722861246\n",
      "Best Parameters:  {'pls__n_components': 9}\n"
     ]
    }
   ],
   "source": [
    "pls_reg = Pipeline([\n",
    "    ('pls', PLSRegression())\n",
    "])\n",
    "\n",
    "pls_grid = dict(\n",
    "    pls__n_components = np.arange(6, 15, 1)\n",
    ")\n",
    "\n",
    "pls_search = modelevaluation.gridsearch(pls_reg, pls_grid, train_x_transformed, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done   3 out of  30 | elapsed:   45.7s remaining:  6.9min\n",
      "[Parallel(n_jobs=32)]: Done   7 out of  30 | elapsed:   51.6s remaining:  2.8min\n",
      "[Parallel(n_jobs=32)]: Done  11 out of  30 | elapsed:   53.5s remaining:  1.5min\n",
      "[Parallel(n_jobs=32)]: Done  15 out of  30 | elapsed:  1.1min remaining:  1.1min\n",
      "[Parallel(n_jobs=32)]: Done  19 out of  30 | elapsed:  6.4min remaining:  3.7min\n",
      "[Parallel(n_jobs=32)]: Done  23 out of  30 | elapsed:  7.2min remaining:  2.2min\n",
      "[Parallel(n_jobs=32)]: Done  27 out of  30 | elapsed:  8.1min remaining:   53.7s\n",
      "[Parallel(n_jobs=32)]: Done  30 out of  30 | elapsed:  8.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score R2 =  0.20392686350784336\n",
      "Best Parameters:  {'alpha': 0.003593813663804626}\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "alphas = np.logspace(-4, -0.5, 10)\n",
    "lasso_grid = [{'alpha': alphas}]\n",
    "lasso_search = modelevaluation.gridsearch(lasso, lasso_grid, train_x_transformed, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done   8 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=32)]: Done  21 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=32)]: Done  34 tasks      | elapsed: 19.0min\n",
      "[Parallel(n_jobs=32)]: Done  49 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=32)]: Done  64 tasks      | elapsed: 22.1min\n",
      "[Parallel(n_jobs=32)]: Done  81 tasks      | elapsed: 24.2min\n",
      "[Parallel(n_jobs=32)]: Done 103 out of 150 | elapsed: 25.4min remaining: 11.6min\n",
      "[Parallel(n_jobs=32)]: Done 119 out of 150 | elapsed: 26.0min remaining:  6.8min\n",
      "[Parallel(n_jobs=32)]: Done 135 out of 150 | elapsed: 28.6min remaining:  3.2min\n",
      "[Parallel(n_jobs=32)]: Done 150 out of 150 | elapsed: 35.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score R2 =  0.2055916255334355\n",
      "Best Parameters:  {'alpha': 0.008799225435691074, 'l1_ratio': 0.25}\n"
     ]
    }
   ],
   "source": [
    "enet = ElasticNet()\n",
    "alphas = np.logspace(-4, -0.5, 10)\n",
    "enet_grid = [{'alpha': alphas, 'l1_ratio' : np.linspace(0, 1, 5)}]\n",
    "enet_search = modelevaluation.gridsearch(enet, enet_grid, train_x_transformed, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating predictions for model: linear_reg\n",
      "generating predictions for model: PLS\n",
      "generating predictions for model: lasso\n",
      "generating predictions for model: enet\n"
     ]
    }
   ],
   "source": [
    "mymodels = {\n",
    "    'linear_reg': lm_search.best_estimator_,\n",
    "    'PLS': pls_search.best_estimator_,\n",
    "    'lasso': lasso_search.best_estimator_,\n",
    "    'enet': enet_search.best_estimator_\n",
    "}\n",
    "modelevaluation.eval_models(mymodels, preprocessing, test_x, test_y).to_csv(\"results_data/val_linearmodels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-FOLD CV\n",
    "\n",
    "Cross validate the best scoring model to have a profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidation(trained_models, n_splits=10):\n",
    "    \"\"\"\n",
    "    evaluate trained models in test data using 10Fold CV\n",
    "    Args:\n",
    "        trained_models (dict): Maps a model name/id (str) to an estimator object\n",
    "    Returns: pd.DataFrame with R2 score for each fold\n",
    "    \"\"\"\n",
    "    cross_val = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    r2score = make_scorer(r2_score)\n",
    "    results = []\n",
    "    for mdlname, estimator in trained_models.items():\n",
    "        print('cv for model: {}'.format(mdlname))\n",
    "        scores = cross_val_score(estimator, train_x_transformed, train_y, cv=cross_val, n_jobs=10, scoring=r2score)\n",
    "        # put results in pandas data frame\n",
    "        res = pd.DataFrame({'r2_score': scores, 'kfold' : range(1, n_splits + 1), 'mdlname': mdlname})\n",
    "        results.append(res)\n",
    "    return pd.concat(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv for model: linear_reg\n",
      "cv for model: PLS\n",
      "cv for model: lasso\n",
      "cv for model: enet\n"
     ]
    }
   ],
   "source": [
    "results = modelevaluation.crossvalidation(mymodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('results_data/cv_linearmodels.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
