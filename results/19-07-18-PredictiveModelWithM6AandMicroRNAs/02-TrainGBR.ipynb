{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GBR in mRNA stability data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import random_integers\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# my module imports\n",
    "from optimalcodon.projects.rnastability.dataprocessing import get_data, general_preprocesing_pipeline2\n",
    "from optimalcodon.projects.rnastability import modelevaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67832 points for training and 7536 for testing with 8 features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(67832, 82)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_x, train_y), (test_x, test_y) = get_data(\"results_data/\")\n",
    "print(\"{} points for training and {} for testing with {} features\".format(\n",
    "    train_x.shape[0], test_x.shape[0], test_x.shape[1]))\n",
    "\n",
    "# pre-processing\n",
    "\n",
    "preprocessing = general_preprocesing_pipeline2(train_x)\n",
    "\n",
    "preprocessing.fit(train_x)\n",
    "train_x_transformed = preprocessing.transform(train_x)\n",
    "\n",
    "train_x_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done   1 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=30)]: Done  12 tasks      | elapsed: 40.2min\n",
      "[Parallel(n_jobs=30)]: Done  25 tasks      | elapsed: 90.3min\n",
      "/home/smedina/anaconda3/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=30)]: Done  38 tasks      | elapsed: 158.4min\n",
      "[Parallel(n_jobs=30)]: Done  53 tasks      | elapsed: 222.8min\n",
      "[Parallel(n_jobs=30)]: Done  68 tasks      | elapsed: 283.3min\n",
      "[Parallel(n_jobs=30)]: Done  85 tasks      | elapsed: 348.9min\n",
      "[Parallel(n_jobs=30)]: Done 102 tasks      | elapsed: 368.4min\n",
      "[Parallel(n_jobs=30)]: Done 121 tasks      | elapsed: 418.2min\n",
      "[Parallel(n_jobs=30)]: Done 140 tasks      | elapsed: 473.8min\n",
      "[Parallel(n_jobs=30)]: Done 162 out of 200 | elapsed: 537.9min remaining: 126.2min\n",
      "[Parallel(n_jobs=30)]: Done 183 out of 200 | elapsed: 587.5min remaining: 54.6min\n",
      "[Parallel(n_jobs=30)]: Done 200 out of 200 | elapsed: 742.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=4, random_state=42, shuffle=True),\n",
       "                   error_score='raise-deprecating',\n",
       "                   estimator=GradientBoostingRegressor(alpha=0.9,\n",
       "                                                       criterion='friedman_mse',\n",
       "                                                       init=None,\n",
       "                                                       learning_rate=0.1,\n",
       "                                                       loss='ls', max_depth=3,\n",
       "                                                       max_features=None,\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_split=2,\n",
       "                                                       m...\n",
       "                   iid='warn', n_iter=50, n_jobs=30,\n",
       "                   param_distributions={'learning_rate': [0.1, 0.055, 0.01,\n",
       "                                                          0.0055, 0.001],\n",
       "                                        'loss': ['huber'],\n",
       "                                        'max_depth': [10, 15, 17, 20],\n",
       "                                        'max_features': ['log2'],\n",
       "                                        'min_samples_leaf': [2, 3],\n",
       "                                        'min_samples_split': [4, 6, 8],\n",
       "                                        'n_estimators': [500, 700, 1000, 1200,\n",
       "                                                         1500, 1700, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='r2', verbose=10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_grid = {'loss':['huber'],\n",
    "          'learning_rate':[0.1, 0.055, 0.01, 0.0055, 0.001],\n",
    "          'n_estimators':[500, 700,1000, 1200, 1500, 1700, 2000],\n",
    "          'min_samples_split':[4, 6, 8],\n",
    "          'min_samples_leaf':[2, 3],\n",
    "          'max_depth':[10, 15, 17, 20],\n",
    "          'max_features':['log2']}\n",
    "\n",
    "# make cross validation to shuffle the data\n",
    "cross_val = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "random_cv = RandomizedSearchCV(estimator=model,\n",
    "                               param_distributions=gbm_grid,\n",
    "                               cv=cross_val, n_iter=50, n_jobs=30,verbose=10,\n",
    "                               scoring='r2')\n",
    "\n",
    "random_cv.fit(train_x_transformed, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.369271501664413"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1700,\n",
       " 'min_samples_split': 8,\n",
       " 'min_samples_leaf': 3,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 10,\n",
       " 'loss': 'huber',\n",
       " 'learning_rate': 0.01}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating predictions for model: gbm\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'gbm': random_cv.best_estimator_\n",
    "}\n",
    "modelevaluation.eval_models(models, preprocessing, test_x, test_y).to_csv(\"results_data/val_gbm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv for model: gbm\n"
     ]
    }
   ],
   "source": [
    "modelevaluation.crossvalidation(models, train_x_transformed, train_y).to_csv('results_data/cv_gbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/n/projects/smedina/projectos/190108-mzt-rna-stability/results/19-07-18-PredictiveModelWithM6AandMicroRNAs'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
