{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn import\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "# cross-validation technique\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold, cross_val_score\n",
    "\n",
    "\n",
    "# my module imports\n",
    "from optimalcodon.projects.rnastability.dataprocessing import get_data, general_preprocesing_pipeline\n",
    "from optimalcodon.projects.rnastability import modelevaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67817 points for training and 7534 for testing with 6 features\n"
     ]
    }
   ],
   "source": [
    "(train_x, train_y), (test_x, test_y) = get_data(\"../19-04-30-PredictiveModelDecayAllSpecies/19-04-30-EDA/results_data/\")\n",
    "\n",
    "# I will test groped cross validation technique\n",
    "groups_cv = train_x.index.values\n",
    "print(\"{} points for training and {} for testing with {} features\".format(\n",
    "    train_x.shape[0], test_x.shape[0], test_x.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Pipeline([\n",
    "    ('general', general_preprocesing_pipeline(train_x)), # see the code for general_preprocesing_pipeline\n",
    "    ('polyfeaturs', PolynomialFeatures(degree=2)),\n",
    "    ('zerovar', VarianceThreshold(threshold=0.0)),\n",
    "    ('scaling', StandardScaler()) # I scale again not all polynomial features may be with scaled\n",
    "])\n",
    "\n",
    "\n",
    "preprocessing.fit(train_x)\n",
    "train_x_transformed = preprocessing.transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_reg = Pipeline([\n",
    "    ('lm', LinearRegression())\n",
    "])\n",
    "\n",
    "lm_grid = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val = GroupKFold(n_splits=10)\n",
    "r2score = make_scorer(r2_score)\n",
    "grid_search = GridSearchCV(estimator=lm_reg, param_grid=lm_grid,\n",
    "                               n_jobs=4, cv=cross_val, verbose=10, scoring=r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 out of  10 | elapsed: 10.9min remaining: 10.9min\n",
      "[Parallel(n_jobs=4)]: Done   7 out of  10 | elapsed: 10.9min remaining:  4.7min\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed: 13.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=GroupKFold(n_splits=10), error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('lm', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=4, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(r2_score), verbose=10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(train_x_transformed, train_y, groups=groups_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1286173537241034"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how do we used it here\n",
    "cross_val = GroupKFold(n_splits=5)\n",
    "cross_val = cross_val.split(train_x_transformed, train_y, groups=groups_cv)\n",
    "\n",
    "r2score = make_scorer(r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cross_val_score(grid_search.best_estimator_, train_x_transformed, train_y, cv=cross_val, n_jobs=4, scoring=r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
